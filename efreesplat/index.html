<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="We propose eFreeSplat, an efficient feed-forward 3DGS-based model for generalizable novel view synthesis that operates independently of epipolar line constraints.">
  <meta name="keywords" content="eFreeSplat, 3DGS, NeRF, generalizable novel view synthesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Epipolar-Free 3D Gaussian Splatting for Generalizable Novel View Synthesis</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-TXFTHRL91M"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-TXFTHRL91M');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://tatakai1.github.io/efreesplat/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/tatakai1/EVENeRF">
            EVE-NeRF
          </a>
          <a class="navbar-item" href="https://tatakai1.github.io/efreesplat/">
            eFreeSplat
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Epipolar-Free 3D Gaussian Splatting for Generalizable Novel View Synthesis</h1>
          <div class="is-size-5 publication-authors">
            <!-- <span class="author-block">
              <a href="https://keunhong.com">Keunhong Park</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Utkarsh Sinha</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Jonathan T. Barron</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Sofien Bouaziz</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
            </span> -->
            <span class="author-block">
              Zhiyuan Min<sup>1</sup>,&nbsp;</span>
            <span class="author-block">
              Yawei Luo<sup>1</sup>,&nbsp;</span>
            <span class="author-block">
              Jianwen Sun<sup>2</sup>,&nbsp;</span>
            <span class="author-block">
              Yi Yang<sup>1</sup>&nbsp;</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup><i>Zhejiang University</i>,&nbsp;</span>
            <span class="author-block"><sup>2</sup><i>Central China Normal University</i>&nbsp;</span>
          </div>

          <div class="column is-full_width">
            <h2 class="title is-4">NeurIPS 2024</h2>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div> -->

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>We propose eFreeSplat, an efficient feed-forward 3DGS-based model for generalizable
            novel view synthesis that operates independently of epipolar line constraints.</p>
          
          <p>To enhance multiview feature extraction with 3D perception, we employ a selfsupervised
            Vision Transformer (ViT) with cross-view completion pre-training on
            large-scale datasets. Additionally, we introduce an Iterative Cross-view Gaussians
            Alignment method to ensure consistent depth scales across different views. Our
            eFreeSplat represents an innovative approach for generalizable novel view synthesis.
            Different from the existing pure geometry-free methods, eFreeSplat focuses
            more on achieving epipolar-free feature matching and encoding by providing 3D
            priors through cross-view pretraining.</p> 
            
          <p>We evaluate eFreeSplat on wide-baseline
          novel view synthesis tasks using the RealEstate10K and ACID datasets. Extensive
          experiments demonstrate that eFreeSplat surpasses state-of-the-art baselines that
          rely on epipolar priors, achieving superior geometry reconstruction and novel view
          synthesis quality.</p>
          <!-- <p>
            We present the first method capable of photorealistically reconstructing a non-rigidly
            deforming scene using photos/videos captured casually from mobile phones.
          </p>
          <p>
            Our approach augments neural radiance fields
            (NeRF) by optimizing an
            additional continuous volumetric deformation field that warps each observed point into a
            canonical 5D NeRF.
            We observe that these NeRF-like deformation fields are prone to local minima, and
            propose a coarse-to-fine optimization method for coordinate-based models that allows for
            more robust optimization.
            By adapting principles from geometry processing and physical simulation to NeRF-like
            models, we propose an elastic regularization of the deformation field that further
            improves robustness.
          </p>
          <p>
            We show that <span class="dnerf">Nerfies</span> can turn casually captured selfie
            photos/videos into deformable NeRF
            models that allow for photorealistic renderings of the subject from arbitrary
            viewpoints, which we dub <i>"nerfies"</i>. We evaluate our method by collecting data
            using a
            rig with two mobile phones that take time-synchronized photos, yielding train/validation
            images of the same pose at different viewpoints. We show that our method faithfully
            reconstructs non-rigidly deforming scenes and reproduces unseen views with high
            fidelity.
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

  <section class="section">
    <div class="container is-max-desktop">

      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Overview</h2>

          <img src="./static/images/pipeline.jpg" class="center">
          <figcaption class="has-text-justified"><b>Overview of eFreeSplat.</b> (a) Epipolar-free Cross-view Mutual Perception leverages selfsupervised
            cross-view completion pre-training to extract robust 3D priors. The ViT with
            shared weights processes the reference images, followed by a cross-attention decoder to generate
            multiview feature maps, forming 3D perception without epipolar priors. (b) Iterative Cross-view
            Gaussians Alignment module iteratively refines Gaussian attributes through a 2D U-Net. The process
            involves warped features to align corresponding features and depths, ensuring consistent depth
            scales across different views. (c) The final step involves employing rasterization-based volume
            rendering to generate high-quality geometry and realistic novel view images.</figcaption>

        </div>
      </div>

    </div>
  </section>


<section class="section" style="padding-top: 0;">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Comparisons with the State-of-the-art</h2>

        <div class="content has-text-justified">
          <p>We present qualitative comparisons with the following state-of-the-art models:</p>
          <ul>
            <li><a href="https://davidcharatan.com/pixelsplat/">pixelSplat</a>: The latest feed-forward 3D Gaussians model
              that utilies data-driven regression architecture to predict Gaussian centers, leading to 
              poor geometry reconstruction and limited ability of cross-dataset generalization.</li>
            <li><a href="https://haofeixu.github.io/murf/">MuRF</a>: The latest feed-forward NeRF model that leverages 
              3D volume and (2+1)D CNN, which is expensive to train and renders comparably slowly.</li>
          </ul>
        </div>

        <img src="./static/images/sota_comparisons.png" class="center" alt="comparison on Real Estate 10k and ACID dataset">
        <div class="content has-text-centered">
          <video id="replay-video" autoplay="" controls="" muted="" preload="" playsinline="" loop="" width="100%">
            <source src="static/videos/sota_comparisons.mp4" type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>


<section class="section" style="padding-top: 0;">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Comparisons of Geometry Reconstruction</h2>

        <div class="content has-text-justified">
          <p>Our MVSplat produces significantly higher-quality 3D Gaussian primitives than the latest state-of-the-art
        pixelSplat. The readers are invited to view the corresponding ".ply" files of the 3D Gaussians exported from
        both models provided at <b><a href="https://drive.google.com/drive/folders/1nBpUQnBvAIL7oLODElhIiLkW9x5gAuWs" target="_blank">HERE</a></b>.
        We recommend viewing them with online viewers, <i>e.g.</i>,
        <a href="https://projects.markkellogg.org/threejs/demo_gaussian_splats_3d.php?art=1&amp;cu=0,0,1&amp;cp=0,1,0&amp;cla=1,0,0" target="_blank">3D Gaussian Splatting with Three.js</a>
        (camera up should be set to "0,0,1").</p>
        </div>

        <img src="./static/images/point_clouds.png" class="center" alt="point clouds and depth maps">
      </div>
    </div>

  </div>
</section>



<section class="section" style="padding-top: 0;">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Comparisons of Cross-dataset Generalization</h2>

        <div class="content has-text-justified">
          <p>Our MVSplat is inherently superior in generalizing to <em>out-of-distribution</em> novel scenes, primarily due to the fact that the
      cost volume captures the <em>relative similarity</em> between features, which remains <em>invariant</em> compared to the absolute scale of
      features. Here, we present cross-dataset generalization by training models solely on RealEstate10K (indoor scenes), and directly 
      test them on DTU (object-centric scenes) and ACID (outdoor scenes).</p>
        </div>

        <img src="./static/images/re10k_generalization.png" class="center" alt="trained on RealEstate10K, and tested on DTU and ACID">
        <div class="content has-text-centered">
          <video id="replay-video" autoplay="" controls="" muted="" preload="" playsinline="" loop="" width="100%">
            <source src="static/videos/re10k_generalization.mp4" type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>



<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Acknowledgements</h2>
    This work was supported by the National Natural Science Foundation of China (62293554, 62206249,
U2336212), "Leading Goose" R&D Program of Zhejiang (No. 2024C01161), and Young Elite
Scientists Sponsorship Program by CAST (2023QNRC001).
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title" style="margin-top: -60px">BibTeX</h2>
    <pre><code>@article{chen2024mvsplat,
    title   = {Epipolar-Free 3D Gaussian Splatting for Generalizable Novel View Synthesis},
    author  = {Chen, Yuedong and Xu, Haofei and Zheng, Chuanxia and Zhuang, Bohan and Pollefeys, Marc and Geiger, Andreas and Cham, Tat-Jen and Cai, Jianfei},
    journal = {arXiv preprint arXiv:2403.14627},
    year    = {2024},
}</code></pre>

  </div>
</section>

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            Template was borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
          under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <!-- <p>Please contact <a href="https://donydchen.github.io/">Yuedong Chen</a> for feedback and questions.</p> -->
        </div>
      </div>
    </div>
  </div>
</footer>


<!-- <footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>
</html>
